---
title: "Random_forest_GC"
author: "Pete Chuckran"
date: "3/24/2021"
output: html_document
---

```{r setup, include=FALSE}
# Random forest analysis 

packages <- c('tidyverse', 'jsonlite','neonUtilities', 'httr', 'ggpmisc', 'GGally',
              'randomForest', 'tidymodels', 'tidypredict', 'ranger', 'vip', 
              'doParallel')

## method for loading all packages, and installing ones that are missing if this is launched on a different rig
lapply(packages, function(x){
  #browser()
  ## if the required package is present (TRUE), load it up
  if (require(x, character.only = TRUE)==TRUE){
    library(x, character.only=TRUE)
  } else {
    install.packages(x)
  }
})


```

_AUSTIN: build in the removal to make happen in the recipe. Also, if trying imputing don't want to remove predictors quite yet._

_Pete: 20210414, Adding the compoentents _

```{r}
# Remove non-predictive data
full_df <- read_csv("../data/input/derived/full_df.csv")
full_df <- full_df %>%
  filter(sampleFilteredReadNumber > 2000000)

# Remove predictors containing < 200 responses
cutoff <- 250
counts_per_paramter <- apply(full_df, 2, function(x) length(which(!is.na(x))))
above_cutoff <- counts_per_paramter[counts_per_paramter > cutoff]
to_keep <- names(above_cutoff)
rf_df <- full_df %>%
  select(to_keep)
```


```{r}
set.seed(41)
# Train and test split, splitting along site
data_split <- initial_split(rf_df, prop = 0.70, strata = 'horizon')
RF_train <- training(data_split)
RF_test <- testing(data_split)

# make folds for k-fold cross-validation
GC_vfold <- vfold_cv(RF_train, v = 5, repeats = 5) # usually min of 5-fold cross-validation

# Build out the recipe, steps are v important 
GC_recipe <- 
  recipe(GC_bact ~ ., data = RF_train) %>% # predict GC_bact
  step_string2factor(ID, siteID,dnaSampleID, soilID, plotID, nlcdClass, horizon) %>% # factors factors not char
  update_role(ID, horizon, siteID, soilID, plotID, new_role = "ID") %>% # make ids for possible back tracking
  step_date(collectDate) %>% # make sure date is date
  step_rm(ID, horizon, siteID, soilID, plotID, collectDate, year, X,
          dnaSampleID, verticalPosition, soilID, sampleTotalReadNumber,
          sampleFilteredReadNumber, reads, plotID, test, GC, Genome_C, Genome_CN, Genome_N, 
          year, Genomes, Nuc_CN, AA_CN, AGS, bp, GC_adj
          ) %>% # remove from model
  step_knnimpute(all_numeric()) %>% # k-nn for imputing
  step_dummy(all_nominal(), -all_outcomes()) %>% # create dummy variables for all char/factor that are not response
  step_normalize(all_predictors()) %>% # center and scale all variables...apples to apples
  step_zv(all_predictors()) %>% #remove zero variance predictors 
  step_poly(soil_OrgCtoN, degree = 3) 

# Apply recipe preprocessing to training data
rf_prepped <- prep(GC_recipe, training = RF_train) # preps data, applies recipe

# Run (bake) prepped preprocessng to training & testing data to see the number of final dummy variables and that recipe works
rf_train_bake <- bake(rf_prepped, new_data = RF_train)

rf_test_bake <- bake(rf_prepped, new_data = RF_test)

# define rf model hyperparams
RF_mod <- rand_forest(mtry = tune(),
                      min_n = tune(),
                      trees = 1000,
                      mode = "regression") %>%
  set_engine("ranger",
             importance = "impurity")

# combine model and recipe into workflow
GC_wflow <- 
  workflow() %>% 
  add_model(RF_mod) %>% 
  add_recipe(GC_recipe)

# Set up the initial tuning grid for finding best mtry and min_n (hyperparameters)
# Match mtry with number of predictor variables (35) following preprocessing divided by three
# Match min_n to sqrt (rounded up) of number of predictor variables (11)
# Expanding tuning grid below because the small one was kinda shit for min_n
rf_param <-
  GC_wflow %>%
  parameters() %>%
  update(mtry = mtry(range = c(1L, 35L)),
         min_n = min_n(range = c(1L, 11L)))

rf_tune_grid <- grid_regular(rf_param, levels = 35)

rf_tune_grid

# below runs the first model, prior to any hyperparameter tuning
# takes about 45min-hour with 4 cores
# takes about 30min with 7 cores
# commenting out just to be safe and don't have parallel set up
#rf_fit_results <- tune_grid(GC_wflow,
#                           resamples = GC_vfold,
#                           grid = rf_tune_grid,
#                           metrics = metric_set(rmse, mae, rsq))

# keep rds of full model to save future memory
#saveRDS(rf_fit_results, "../data/input/random_forest/GCBact_model_RF_full.rds")

rf_fit_results <- readRDS("../data/input/random_forest/GCBact_model_RF_full.rds")

rf_param_plot <- rf_fit_results %>%
  collect_metrics() %>%
  dplyr::filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry) %>%
  tidyr::pivot_longer(min_n:mtry,
                      values_to = "value",
                      names_to = "parameter") %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

rf_param_plot

# Look at best random forest models based on the Mean Absolute Error (and/or RMSE)
show_best(rf_fit_results, metric = "mae")
show_best(rf_fit_results, metric = "rmse")

# Update tuning grid based on best +1, -1 range of min_n and mtry
rf_grid_update <- grid_regular(
  mtry(range = c(18, 34)),
  min_n(range = c(1, 3)),
  levels = 32)

#rf_fit_update <- tune_grid(GC_wflow, 
#                           resamples = GC_vfold,
#                           grid = rf_grid_update,
#                           metrics = metric_set(rmse, mae, rsq))

#saveRDS(rf_fit_update, "../data/input/random_forest/GCBact_model_RF_small.rds")

rf_fit_update<-readRDS("../data/input/random_forest/GCBact_model_RF_small.rds")

show_best(rf_fit_update, metric = "rmse")
show_best(rf_fit_update, metric = "mae")
show_best(rf_fit_update, metric = "rsq")

# Pull out parameters of the best model based on RMSE (for prediction)
rf_best <- rf_fit_update %>% select_by_pct_loss(mtry, metric = "rmse")

# Finalize the model with the parameters of the best selected model
final_rf <- finalize_model(RF_mod, rf_best)

# Rerun final model and output the variable importance based on the GINI index, point is ID only
rf_fit_train <- final_rf %>%
  fit(GC_bact ~ .,
      data = rf_train_bake)

rf_vip_train <- rf_fit_train %>%
  vip(geom = "point", num_features = 10) # variable importance graph

rf_vip_train

# check if same VIPs come out with test data
rf_vip_test <- final_rf %>%
  fit(GC_bact ~ .,
      data = rf_test_bake) %>%
  vip(geom = "point", num_features = 10) # variable importance graph

rf_vip_test


# Finalize Workflow
final_wf <- workflow() %>%
  add_recipe(GC_recipe) %>%
  add_model(final_rf)

# Apply last workflow to training and testing data
final_res <- final_wf %>%
  last_fit(data_split)

# Look at final model performance metrics (mae, rmse, rsq)
final_res %>%
  collect_metrics()


show_best(final_res, metric = "rmse")
show_best(final_res, metric = "rsq")

# Compare predicted GC_bact values to test GC_bact
final_res %>% 
  collect_predictions(summarize = FALSE) %>% arrange(desc(GC_bact))

# Graph of predicted values to testing pwc
rf_plot <- final_res %>%
  collect_predictions() %>%
  ggplot(aes(GC_bact, .pred)) +
  geom_point(size = 0.5, alpha = 0.5) +
  labs(y = 'Random Forest Predicted GC_bact', x = 'Original GC_bact') +
  scale_color_manual(values = c("gray80", "darkred"))+
  geom_abline(intercept = 0, slope = 1, color = "blue", size = 1)+
  stat_smooth(method = "lm", formula = y ~ x, color = "red")+
  ggpmisc::stat_poly_eq(formula = y ~ x, 
                        aes(label =  paste(stat(eq.label),
                                           stat(rr.label), #stat(p.value.label), 
                                           sep = "*\", \"*")),
                        parse = TRUE)+
  theme_bw()

rf_plot
```


```{r}
# Get variables similar to that in RF, just numeric though
for_cor_matrix <- rf_df %>% select(-c(ID, horizon, siteID, soilID, plotID, collectDate, year, X,
          dnaSampleID, verticalPosition, soilID, sampleTotalReadNumber,
          sampleFilteredReadNumber, reads, plotID, test, GC, Genome_C, Genome_CN, Genome_N, 
          year, Genomes, Nuc_CN, AA_CN, AGS, bp, GC_adj, GC_bact))%>% 
  select(where(is.numeric))

# Correlation matrix for numeric features
cor_matrix <- cor(for_cor_matrix, use = "pairwise.complete.obs")

#get list of variable importance
importance_rd1 <- rf_fit_train$fit$variable.importance
# order it by importance
importance_rd1_ordered <- importance_rd1[order(importance_rd1, decreasing = T)]
# initialize output vectors
nonredundant_features <- vector()
redundant_features <- vector()
# find nonredundant important features
for(var in 1:length(importance_rd1_ordered)){
  feat_name <- names(importance_rd1_ordered[var])
  print(feat_name)
  ## Check the feature is in the correlation matrix
  if(feat_name %in% colnames(cor_matrix)){
    # Get correlations for that feature
    corr_feat <- cor_matrix[,feat_name]
    # Gather those with a pearsons > 0.8
    highly_corr <- corr_feat[abs(corr_feat) > 0.8]
    # Get features (if any) which are redundant 
    redundant_test <- names(highly_corr) %in% nonredundant_features
    # Are there any redundant features?
    if(any(redundant_test)){
      # print redundant features
      print("redundant with:")
      print(highly_corr[redundant_test])
      redundant_features <- c(redundant_features, feat_name)
      }else{
        # keep unique important features
      print("keep")
      nonredundant_features <- c(nonredundant_features, feat_name)
      }
          }else{
            print("not in corr matrix")
            }
  
}


nonredundant_features
```


```{r}

# Build out the recipe, steps are v important 
GC_recipe <- 
  recipe(GC_bact ~ ., data = RF_train) %>% # predict GC_bact
  step_string2factor(ID, siteID,dnaSampleID, soilID, plotID, nlcdClass, horizon) %>% # factors factors not char
  update_role(ID, horizon, siteID, soilID, plotID, new_role = "ID") %>% # make ids for possible back tracking
  step_date(collectDate) %>% # make sure date is date
  step_rm(ID, horizon, siteID, soilID, plotID, collectDate, year, X,
          dnaSampleID, verticalPosition, soilID, sampleTotalReadNumber,
          sampleFilteredReadNumber, reads, plotID, test, GC, Genome_C, Genome_CN, Genome_N, 
          year, Genomes, Nuc_CN, AA_CN, AGS, bp, GC_adj
          ) %>% # remove from model
  step_rm(redundant_features)%>%
  step_knnimpute(all_numeric()) %>% # k-nn for imputing
  step_dummy(all_nominal(), -all_outcomes()) %>% # create dummy variables for all char/factor that are not response
  step_normalize(all_predictors()) %>% # center and scale all variables...apples to apples
  step_zv(all_predictors()) %>% #remove zero variance predictors 
  step_poly(soil_OrgCtoN, degree = 3) %>%
  step_poly(phH2o, degree = 3) 

# Apply recipe preprocessing to training data
rf_prepped <- prep(GC_recipe, training = RF_train) # preps data, applies recipe

# Run (bake) prepped preprocessng to training & testing data to see the number of final dummy variables and that recipe works
rf_train_bake <- bake(rf_prepped, new_data = RF_train)

rf_test_bake <- bake(rf_prepped, new_data = RF_test)

# define rf model hyperparams
RF_mod <- rand_forest(mtry = tune(),
                      min_n = tune(),
                      trees = 1000,
                      mode = "regression") %>%
  set_engine("ranger",
             importance = "impurity")

# combine model and recipe into workflow
GC_wflow <- 
  workflow() %>% 
  add_model(RF_mod) %>% 
  add_recipe(GC_recipe)

# Set up the initial tuning grid for finding best mtry and min_n (hyperparameters)
# Match mtry with number of predictor variables (35) following preprocessing divided by three
# Match min_n to sqrt (rounded up) of number of predictor variables (11)
# Expanding tuning grid below because the small one was kinda shit for min_n
rf_param <-
  GC_wflow %>%
  parameters() %>%
  update(mtry = mtry(range = c(1L, 35L)),
         min_n = min_n(range = c(1L, 11L)))

rf_tune_grid <- grid_regular(rf_param, levels = 35)

rf_tune_grid

# below runs the first model, prior to any hyperparameter tuning
# takes about 45min-hour with 4 cores
# takes about 30min with 7 cores
# commenting out just to be safe and don't have parallel set up
#rf_fit_results <- tune_grid(GC_wflow,
#                           resamples = GC_vfold,
#                           grid = rf_tune_grid,
#                           metrics = metric_set(rmse, mae, rsq))

# keep rds of full model to save future memory
#saveRDS(rf_fit_results, "../data/input/random_forest/GCBact_model_RF_sub.rds")

rf_fit_results <- readRDS("../data/input/random_forest/GCBact_model_RF_sub.rds")

rf_param_plot <- rf_fit_results %>%
  collect_metrics() %>%
  dplyr::filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry) %>%
  tidyr::pivot_longer(min_n:mtry,
                      values_to = "value",
                      names_to = "parameter") %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

rf_param_plot

# Look at best random forest models based on the Mean Absolute Error (and/or RMSE)
show_best(rf_fit_results, metric = "mae")
show_best(rf_fit_results, metric = "rmse")

# Update tuning grid based on best +1, -1 range of min_n and mtry
rf_grid_update <- grid_regular(
  mtry(range = c(18, 34)),
  min_n(range = c(1, 3)),
  levels = 32)

#rf_fit_update <- tune_grid(GC_wflow, 
#                           resamples = GC_vfold,
#                           grid = rf_grid_update,
#                           metrics = metric_set(rmse, mae, rsq))

#saveRDS(rf_fit_update, "../data/input/random_forest/GCBact_model_RF_sub_small.rds")

rf_fit_update<-readRDS("../data/input/random_forest/GCBact_model_RF_sub_small.rds")

show_best(rf_fit_update, metric = "rmse")
show_best(rf_fit_update, metric = "mae")
show_best(rf_fit_update, metric = "rsq")

# Pull out parameters of the best model based on RMSE (for prediction)
rf_best <- rf_fit_update %>% select_by_pct_loss(mtry, metric = "rmse")

# Finalize the model with the parameters of the best selected model
final_rf <- finalize_model(RF_mod, rf_best)

# Rerun final model and output the variable importance based on the GINI index, point is ID only
rf_fit_train <- final_rf %>%
  fit(GC_bact ~ .,
      data = rf_train_bake)

rf_vip_train <- rf_fit_train %>%
  vip(geom = "point", num_features = 10) # variable importance graph

rf_vip_train

# check if same VIPs come out with test data
rf_vip_test <- final_rf %>%
  fit(GC_bact ~ .,
      data = rf_test_bake) %>%
  vip(geom = "point", num_features = 10) # variable importance graph

rf_vip_test


# Finalize Workflow
final_wf <- workflow() %>%
  add_recipe(GC_recipe) %>%
  add_model(final_rf)

# Apply last workflow to training and testing data
final_res <- final_wf %>%
  last_fit(data_split)

# Look at final model performance metrics (mae, rmse, rsq)
final_res %>%
  collect_metrics()


show_best(final_res, metric = "rmse")
show_best(final_res, metric = "rsq")

# Compare predicted GC_bact values to test GC_bact
final_res %>% 
  collect_predictions(summarize = FALSE) %>% arrange(desc(GC_bact))

# Graph of predicted values to testing pwc
rf_plot <- final_res %>%
  collect_predictions() %>%
  ggplot(aes(GC_bact, .pred)) +
  geom_point(size = 0.5, alpha = 0.5) +
  labs(y = 'Random Forest Predicted GC_bact', x = 'Original GC_bact') +
  scale_color_manual(values = c("gray80", "darkred"))+
  geom_abline(intercept = 0, slope = 1, color = "blue", size = 1)+
  stat_smooth(method = "lm", formula = y ~ x, color = "red")+
  ggpmisc::stat_poly_eq(formula = y ~ x, 
                        aes(label =  paste(stat(eq.label),
                                           stat(rr.label), #stat(p.value.label), 
                                           sep = "*\", \"*")),
                        parse = TRUE)+
  theme_bw()

rf_plot
```


```{r}
rf_vip_train <- rf_fit_train %>%
  vip(geom = "point", num_features = 10)

theme_pete<- function(base_size = 14) {
  theme_bw(base_size = base_size) %+replace%
    theme(
      strip.background =element_blank(),
      strip.placement = "outside",
      #panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.grid.major.x = element_blank()
    )
}

Fig_3a <- rf_vip_train+
  theme_pete()+
  geom_point(size = 4, shape = 21, fill = "darkred")
Fig_3a

ggsave(plot = Fig_3a, filename = "../paper/figures/Fig3a.png")
```


