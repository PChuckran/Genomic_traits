packages <- c('tidyverse', 'jsonlite','neonUtilities', 'httr')
## a more robust method for loading all packages, and installing ones that are missing if this is launched on a different rig
lapply(packages, function(x){
#browser()
## if the required package is present (TRUE), load it up
if (require(x, character.only = TRUE)==TRUE){
library(x, character.only=TRUE)
} else {
install.packages(x)
}
})
source('~/GitHub/frida/code/getdata/get_data_nongenomic.R')
soilphys <- loadByProduct(dpID=dpid1, site = all, token=Sys.getenv('NEON_API_TOKEN'))
soilphys <- loadByProduct(dpID=dpid1, site = all, token=Sys.getenv('NEON_API_TOKEN'))
### physical, isotope, and chemical properties
dpid1 <- 'DP1.10086.001'
soilphys <- loadByProduct(dpID=dpid1, site = all, token=Sys.getenv('NEON_API_TOKEN'))
soilphys <- loadByProduct(dpID=dpid1, site = all, token=Sys.getenv('NEON_TOKEN'))
soilphys <- loadByProduct(dpID=dpid1, site = 'all', token=Sys.getenv('NEON_TOKEN'))
last_run <- Sys.Date()
## list of soil related data products
soil_products <- list(
dpid1 <- 'DP1.10086.001', ### physical, isotope, and chemical properties
dpid2 <- 'DP1.10107.001', ### soil metagenomic sequences
dpid3 <- 'DP1.10109.001', ### soil microbial group abundances
dpid4 <- 'DP1.10104.001', ### soil microbial biomass
dpid5 <- 'DP1.10108.001' ### soil marker genes
)
soil_products
## list of soil related data products
soil_products <- c(
dpid1 <- 'DP1.10086.001', ### physical, isotope, and chemical properties
dpid2 <- 'DP1.10107.001', ### soil metagenomic sequences
dpid3 <- 'DP1.10109.001', ### soil microbial group abundances
dpid4 <- 'DP1.10104.001', ### soil microbial biomass
dpid5 <- 'DP1.10108.001' ### soil marker genes
)
soil_products[1]
soil_products[1] <- NULL
soil_products[1] <- ''
last_run <- Sys.Date()
data_list <- lapply(soil_products, FUN = function(x){
data <- loadByProduct(dpID = x, site = 'all', token=Sys.getenv('NEON_TOKEN'), check.size=FALSE)
return(data)
})
soil_products[1]
soil_products[1] <- NULL
data_list <- lapply(soil_products[2:length(soil_products)], FUN = function(x){
data <- loadByProduct(dpID = x, site = 'all', token=Sys.getenv('NEON_TOKEN'), check.size=FALSE)
return(data)
})
siz
write.csv(last_run, 'last_run_getdata.csv', row.names=FALSE)
# Making the big DF to use in analyses
packages <- c('tidyverse', 'jsonlite','neonUtilities', 'httr', 'ggpmisc', 'GGally',
'randomForest', 'sp', 'rgeos')
## method for loading all packages, and installing ones that are missing if this is launched on a different rig
lapply(packages, function(x){
#browser()
## if the required package is present (TRUE), load it up
if (require(x, character.only = TRUE)==TRUE){
library(x, character.only=TRUE)
} else {
install.packages(x)
}
})
#### load custom functions, if any
file_sources <- list.files(file.path( 'code/functions'), pattern="*.R$",
full.names=TRUE, ignore.case=TRUE)
file_sources <- base::tryCatch(invisible(sapply(file_sources, source, .GlobalEnv)),
error = function(e) {
base::stop()
})
spei <- read.csv("data/input/derived/spei.csv")%>%
select(-c(X, collectDate))
packages <- c('tidyverse', 'jsonlite','neonUtilities', 'httr', 'lubridate')
lapply(packages, function(x){
#browser()
## if the required package is present (TRUE), load it up
if (require(x, character.only = TRUE)==TRUE){
library(x, character.only=TRUE)
} else {
install.packages(x)
}
})
moisture_summary <- data.frame()
#### load custom functions, if any
file_sources <- list.files(file.path('code', 'functions'), pattern="*.R$",
full.names=TRUE, ignore.case=TRUE)
file_sources <- base::tryCatch(invisible(sapply(file_sources, source, .GlobalEnv)),
error = function(e) {
base::stop()
})
NEON_TOKEN = "eyJ0eXAiOiJKV1QiLCJhbGciOiJFUzI1NiJ9.eyJhdWQiOiJodHRwczovL2RhdGEubmVvbnNjaWVuY2Uub3JnL2FwaS92MC8iLCJzdWIiOiJwZmMyNUBuYXUuZWR1Iiwic2NvcGUiOiJyYXRlOnB1YmxpYyIsImlzcyI6Imh0dHBzOi8vZGF0YS5uZW9uc2NpZW5jZS5vcmcvIiwiZXhwIjoxNzcxODgzNTE4LCJpYXQiOjE2MTQyMDM1MTgsImVtYWlsIjoicGZjMjVAbmF1LmVkdSJ9.p9fxkL6DbB6UOjc3YR2xw4nnsFilURlh3_-bme5gLu3IUbMVVUdSzrs_oXhgLNsgq9-p2G_lU15-dHwyofS2bQ"
samples <- read.csv("code/getdata/moisture_to_get.csv") %>%
select(siteID)
samples <- read.csv("moisture_to_get.csv") %>%
select(siteID)
samples$siteID <- as.character(samples$siteID)
# remove duplicates
samples <- subset(samples, !(siteID %in% unique(moisture_summary$siteID)))
samples <- samples[!duplicated(samples$siteID),]
# remove duplicates
samples <- subset(samples, !(siteID %in% unique(moisture_summary$siteID)))
samples <- read.csv("moisture_to_get.csv") %>%
select(siteID)
samples$siteID <- as.character(samples$siteID)
samples <- samples[!duplicated(samples$siteID),]
samples <- read.csv("moisture_to_get.csv") %>%
select(siteID)
samples$siteID <- as.character(samples$siteID)
# remove duplicates
samples <- subset(samples, !(siteID %in% unique(moisture_summary$siteID)))
View(samples)
unique(moisture_summary$siteID)
samples <- samples[!duplicated(samples$siteID),]
unique(moisture_summary$siteID)
duplicated(samples$siteID)
samples <- read.csv("moisture_to_get.csv") %>%
select(siteID)
samples$siteID <- as.character(samples$siteID)
# remove duplicates, provides list of site names
samples <- subset(samples, !(siteID %in% unique(moisture_summary$siteID)))
samples <- samples[!duplicated(samples$siteID),]
get_moisture_fun <- function(site_to_get, toke){
data <- loadByProduct(dpID = 'DP1.00094.001', site = site_to_get, token=toke, check.size=F, package = "basic",
startdate = '2018-01-01', enddate = '2019-12-31',
timeIndex = 30)
sws_30 <- data$SWS_30_minute
sws_30$endDateTime <- as.Date(sws_30$endDateTime)
sws_30$doy <- as.character(strftime(sws_30$endDateTime, format = "%j"))
sws_30$year <- format(as.Date(sws_30$endDateTime, format="%Y-%m-%d"),"%Y")
sws_30_sumDay <- sws_30 %>%
select(-c(startDateTime)) %>%
group_by(verticalPosition, doy, year, endDateTime) %>%
summarise_all(funs(mean), na.rm = T)
sws_30_Ann <- sws_30_sumDay %>%
filter(VSWCMean != "NaN")%>%
#for each year, gather summary statistics
group_by(verticalPosition, year) %>%
summarise(
VSWC_ann_mean = mean(VSWCMean, na.rm = T),
VSWC_ann_var = sd(VSWCMean, na.rm = T),
VSWC_max = max(VSWCMean, na.rm = T),
VSWC_min = min(VSWCMean, na.rm = T),
VSWC_median = median(VSWCMean, na.rm = T),
VSWC_range = VSWC_max - VSWC_min,
VSIC_ann_mean = mean(VSICMean, na.rm = T),
VSIC_ann_var = sd(VSICMean, na.rm = T),
VSIC_max = max(VSICMean, na.rm = T),
VSIC_min = min(VSICMean, na.rm = T),
VSIC_median = median(VSICMean, na.rm = T),
VSIC_range = VSIC_max - VSIC_min,
days = n_distinct(doy)
) %>%
# Average across years
select(-year)%>%
group_by(verticalPosition)%>%
summarise_all(funs(mean), na.rm = T) %>%
mutate(siteID = "BARR")
return(sws_30_Ann)
}
moisture_summary <- data.frame()
packages <- c('tidyverse')
## method for loading all packages, and installing ones that are missing if this is launched on a different rig
lapply(packages, function(x){
#browser()
## if the required package is present (TRUE), load it up
if (require(x, character.only = TRUE)==TRUE){
library(x, character.only=TRUE)
} else {
install.packages(x)
}
})
#### load custom functions, if any
file_sources <- list.files(file.path( 'code/functions'), pattern="*.R$",
full.names=TRUE, ignore.case=TRUE)
file_sources <- base::tryCatch(invisible(sapply(file_sources, source, .GlobalEnv)),
error = function(e) {
base::stop()
})
#### load custom functions, if any
file_sources <- list.files(file.path( '../../code/functions'), pattern="*.R$",
full.names=TRUE, ignore.case=TRUE)
file_sources <- base::tryCatch(invisible(sapply(file_sources, source, .GlobalEnv)),
error = function(e) {
base::stop()
})
#### load custom functions, if any
file_sources <- list.files(file.path( '../../code/functions'), pattern="*.R$",
full.names=TRUE, ignore.case=TRUE)
file_sources <- base::tryCatch(invisible(sapply(file_sources, source, .GlobalEnv)),
error = function(e) {
base::stop()
})
metagenomes <- get_metagenomic()%>%
mutate(collectDate = as.Date(collectDate))
